server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /var/lib/promtail/positions.yaml

clients:
  - url: ${LOKI_URL:http://loki:3100/loki/api/v1/push}
    batchsize: 100
    backoff_config:
      max_period: 5s

scrape_configs:
  - job_name: system-logs
    static_configs:
      - targets: ['localhost']
        labels:
          job: varlogs
          __path__: /var/log/**/*.log

  - job_name: journal
    journal:
      max_age: 12h
    relabel_configs:
      - source_labels: ['__journal__system_unit']
        target_label: 'unit'

pipeline_stages:
  - regex:
      expression: '^(?P<ts>\S+) (?P<lvl>\w+) (?P<msg>.*)$'
    # optional, only if your logs follow a simple prefix format; harmless if not

  - json:
      expressions:
        level: level
        msg: message
      source: msg
      optional: true

  - labels:
      level:

  - drop:
      expression: 'level="debug"'   # drop debug-level logs by default to save storage

  - drop:
      expression: 'msg =~ "heartbeat|keepalive|ping"'  # drop heartbeat lines

limits_config:
  max_line_size: 1048576  # 1 MB - reject/truncate extremely large lines
  # client and target limits can be added if needed

# Configure minimal resource-friendly options
# Promtail keeps small in-memory buffers and uses the positions file on disk to resume tails.
# For heavy hosts, consider running promtail as a sidecar in docker with limited resources.

# Notes:
# - Set LOKI_URL env var on each host to the reachable Loki endpoint (e.g., https://loki.example.com:443/loki/api/v1/push)
# - The positions file path must be writable by promtail (run as a system user with permission to /var/lib/promtail).
# - Tune 'drop' pipeline stages to avoid storing noisy messages that aren't useful.
